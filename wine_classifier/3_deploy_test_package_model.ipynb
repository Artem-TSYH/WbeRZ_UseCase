{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f6e590a",
   "metadata": {},
   "source": [
    "* deploy model locally\n",
    "* send prediction requests to the locally deployed model\n",
    "* generate Dockerfile\n",
    "* Build and deploy the model to the OpenShift Cluster\n",
    "* send prediction requests to the deployed model to the OpenShift Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "093bf78c-041f-44ed-9735-e1582cbf770a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sb\n",
    "\n",
    "import mlflow\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    " \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5639758-1d77-475d-87da-6787a1b5e8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !set MLFLOW_TRACKING_URL=\"http://mlflow-route-mlflow.apps.cluster-qswsm.sandbox775.opentlc.com\"\n",
    "# !set MLFLOW_TRACKING_USERNAME=user\n",
    "# !set MLFLOW_TRACKING_PASSWORD=user\n",
    "import os\n",
    "\n",
    "# os.environ[\"MLFLOW_TRACKING_URI\"] = \"http://mlflow-route-mlflow.apps.cluster-qswsm.sandbox775.opentlc.com\"\n",
    "# os.environ[\"MLFLOW_TRACKING_URI\"] = \"http://127.0.0.1:8000\"\n",
    "# os.env[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2f3227a-21c2-4675-887d-e37a2548b22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model from mlflow in loaded_model\n",
    "MODEL_NAME = \"ElasticnetWineModel\"\n",
    "MODEL_VERSION= 1\n",
    "MODEL_URI = f\"models:/{MODEL_NAME}/{MODEL_VERSION}\"\n",
    "loaded_model = mlflow.pyfunc.load_model(MODEL_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e1c1333-9434-4f1e-96f6-41dffbe57a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6 entries, 0 to 5\n",
      "Data columns (total 13 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         6 non-null      float64\n",
      " 1   volatile acidity      6 non-null      float64\n",
      " 2   citric acid           6 non-null      float64\n",
      " 3   residual sugar        6 non-null      float64\n",
      " 4   chlorides             6 non-null      float64\n",
      " 5   free sulfur dioxide   6 non-null      int64  \n",
      " 6   total sulfur dioxide  6 non-null      int64  \n",
      " 7   density               6 non-null      float64\n",
      " 8   pH                    6 non-null      float64\n",
      " 9   sulphates             6 non-null      float64\n",
      " 10  alcohol               6 non-null      float64\n",
      " 11  quality               6 non-null      int64  \n",
      " 12  best quality          6 non-null      int64  \n",
      "dtypes: float64(9), int64(4)\n",
      "memory usage: 752.0 bytes\n"
     ]
    }
   ],
   "source": [
    "# Test the performance of the Model, which is loaded in the last step, on 6 data points\n",
    "df_test = pd.read_csv('testing_data/winequality-red-test.csv')\n",
    "df_test['best quality'] = [1 if x > 5 else 0 for x in df_test.quality]\n",
    "#print(df_test.head())\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d889a31-0653-4a34-9e59-f44f23519151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted Class  Actual Class\n",
      "0                0             0\n",
      "1                1             0\n",
      "2                0             0\n",
      "3                1             1\n",
      "4                1             1\n",
      "5                1             1\n"
     ]
    }
   ],
   "source": [
    "# Prepare the test input by dropping unnecessary columns\n",
    "df_test_input = df_test.drop(['quality', 'best quality'], axis=1)\n",
    "\n",
    "# Extract the actual class for the test examples\n",
    "actual_class_test = df_test['best quality']\n",
    "\n",
    "# actual_class_test = pd.Series(df_test_actual_class)\n",
    "#print(actual_class_test)\n",
    "\n",
    "# Use the trained model to predict the class for the test input\n",
    "# predicted_class_test = pd.DataFrame(model_logreg.predict(df_test_input))\n",
    "predicted_class_test = pd.DataFrame(loaded_model.predict(df_test_input), columns=['Predicted Class'])\n",
    "\n",
    "# Combine predicted and actual classes into a single DataFrame\n",
    "# model_output = pd.concat([predicted_class_test, actual_class_test], axis=1, ignore_index=True)\n",
    "model_output = pd.concat([predicted_class_test, actual_class_test.reset_index(drop=True)], axis=1)\n",
    "\n",
    "\n",
    "# Rename columns for clarity\n",
    "# model_output = model_output.set_axis(['Predicted Class', 'Actual Class'], axis='columns')\n",
    "model_output.columns = ['Predicted Class', 'Actual Class']\n",
    "\n",
    "print(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d5763c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'index': [0, 1, 2, 3, 4, 5],\n",
       " 'columns': ['fixed acidity',\n",
       "  'volatile acidity',\n",
       "  'citric acid',\n",
       "  'residual sugar',\n",
       "  'chlorides',\n",
       "  'free sulfur dioxide',\n",
       "  'total sulfur dioxide',\n",
       "  'density',\n",
       "  'pH',\n",
       "  'sulphates',\n",
       "  'alcohol'],\n",
       " 'data': [[7.1, 0.875, 0.05, 5.7, 0.082, 3, 14, 0.99808, 3.4, 0.52, 10.2],\n",
       "  [8.5, 0.4, 0.4, 6.3, 0.05, 3, 10, 0.99566, 3.28, 0.56, 12.0],\n",
       "  [7.5, 0.4, 0.18, 1.6, 0.079, 24, 58, 0.9965, 3.34, 0.58, 9.4],\n",
       "  [6.7, 0.46, 0.24, 1.7, 0.077, 18, 34, 0.9948, 3.39, 0.6, 10.6],\n",
       "  [7.3, 0.34, 0.33, 2.5, 0.064, 21, 37, 0.9952, 3.35, 0.77, 12.1],\n",
       "  [7.4, 0.36, 0.3, 1.8, 0.074, 17, 24, 0.99419, 3.24, 0.7, 11.4]]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_input.to_dict(orient ='split')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5665149d",
   "metadata": {},
   "source": [
    "### Run this command in git bash to start a model server locally:\n",
    "*mlflow models serve -m \"models:/ElasticnetWineModel/1\" --env-manager local --no-conda*\n",
    "\n",
    "when it is running, we can send prediction requests to the endpoint: *\"http://127.0.0.1:5000/invocations\"*, as in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9d4521f-033a-4bd3-ad17-f8b650bcdc71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted Wine Quality  Actual Wine Quality\n",
      "0                       0                    0\n",
      "1                       1                    0\n",
      "2                       0                    0\n",
      "3                       1                    1\n",
      "4                       1                    1\n",
      "5                       1                    1\n"
     ]
    }
   ],
   "source": [
    "# Send a prediction request to the depoloyed model\n",
    "import requests\n",
    "\n",
    "inference_request = {\n",
    "    \"dataframe_split\": \n",
    "        df_test_input.to_dict(orient ='split')\n",
    "}\n",
    "\n",
    "endpoint = \"http://127.0.0.1:5000/invocations\"\n",
    "# endpoint = \"http://mlmodel-route-mlmodel.apps.cluster-qswsm.sandbox775.opentlc.com/invocations\"\n",
    "response = requests.post(endpoint, json=inference_request)\n",
    "\n",
    "# response.json()\n",
    "# Check if the response is successful\n",
    "if response.status_code == 200:\n",
    "    # Process the prediction response\n",
    "    # print(response.json())\n",
    "    predictions = pd.DataFrame(response.json()['predictions'], columns=['Predicted Wine Quality'])\n",
    "\n",
    "    # Combine predictions with actual classes\n",
    "    actual_class_test = df_test['best quality'].reset_index(drop=True)\n",
    "    model_output = pd.concat([predictions, actual_class_test], axis=1)\n",
    "\n",
    "    # Rename columns for clarity\n",
    "    model_output.columns = ['Predicted Wine Quality', 'Actual Wine Quality']\n",
    "\n",
    "    # Display the final output\n",
    "    print(model_output)\n",
    "else:\n",
    "    print(f\"Request failed with status code: {response.status_code}\")\n",
    "    print(f\"Response content: {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0c30fd2-a9e8-4406-a5e0-8f4aecc3eb37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/27 11:09:47 INFO mlflow.models.cli: Generating Dockerfile for model models:/ElasticnetWineModel/1\n",
      "\n",
      "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "Downloading artifacts:  17%|█▋        | 1/6 [00:00<?, ?it/s]\n",
      "Downloading artifacts:  33%|███▎      | 2/6 [00:00<?, ?it/s]\n",
      "Downloading artifacts:  50%|█████     | 3/6 [00:00<?, ?it/s]\n",
      "Downloading artifacts:  67%|██████▋   | 4/6 [00:00<?, ?it/s]\n",
      "Downloading artifacts:  83%|████████▎ | 5/6 [00:00<?, ?it/s]\n",
      "Downloading artifacts: 100%|██████████| 6/6 [00:00<?, ?it/s]\n",
      "Downloading artifacts: 100%|██████████| 6/6 [00:00<?, ?it/s]\n",
      "2025/01/27 11:09:48 INFO mlflow.models.flavor_backend_registry: Selected backend for flavor 'python_function'\n",
      "\n",
      "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "Downloading artifacts:  17%|█▋        | 1/6 [00:00<?, ?it/s]\n",
      "Downloading artifacts:  33%|███▎      | 2/6 [00:00<?, ?it/s]\n",
      "Downloading artifacts:  50%|█████     | 3/6 [00:00<?, ?it/s]\n",
      "Downloading artifacts:  67%|██████▋   | 4/6 [00:00<?, ?it/s]\n",
      "Downloading artifacts:  83%|████████▎ | 5/6 [00:00<?, ?it/s]\n",
      "Downloading artifacts: 100%|██████████| 6/6 [00:00<?, ?it/s]\n",
      "Downloading artifacts: 100%|██████████| 6/6 [00:00<?, ?it/s]\n",
      "2025/01/27 11:09:48 INFO mlflow.models.cli: Generated Dockerfile in directory wine_clf_package\n"
     ]
    }
   ],
   "source": [
    "# Create Dockerfile with the name\"wine_classifier_1\":\n",
    "!mlflow models generate-dockerfile -m \"{MODEL_URI}\" --env-manager local -d wine_clf_package --enable-mlserver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61732f1-ba6a-4631-8d67-7a547c055e7e",
   "metadata": {},
   "source": [
    "### It is time to build and deploy the model onto the OpenShift Clsuter\n",
    "\n",
    "1. First push this new generated directory with Dockerfile and model artifacts to the preferred git (GitHub / GitLab / Azure DevOps / ...) Repository. \n",
    "2. Then we go to OpenShift Console to start a Build Process to package the model in an Image\n",
    "3. Deploy the Image onto thhe OpenShift Cluster. \n",
    "4. We come back to test the deployed model on the Cluster from this Jupyter NoteBook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f7316c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted Wine Quality  Actual Wine Quality\n",
      "0                       0                    0\n",
      "1                       1                    0\n",
      "2                       0                    0\n",
      "3                       1                    1\n",
      "4                       1                    1\n",
      "5                       1                    1\n"
     ]
    }
   ],
   "source": [
    "# Send a prediction request to the depoloyed model\n",
    "import requests\n",
    "\n",
    "inference_request = {\n",
    "    \"dataframe_split\": \n",
    "        df_test_input.to_dict(orient ='split')\n",
    "}\n",
    "\n",
    "BASE_URL = \"http://test-clf-app-test.apps.cluster-db46l.dynamic.redhatworkshops.io\"\n",
    "endpoint = f\"{BASE_URL}/invocations\"\n",
    "response = requests.post(endpoint, json=inference_request)\n",
    "\n",
    "# response.json()\n",
    "# Check if the response is successful\n",
    "if response.status_code == 200:\n",
    "    # Process the prediction response\n",
    "    # print(response.json())\n",
    "    predictions = pd.DataFrame(response.json()['predictions'], columns=['Predicted Wine Quality'])\n",
    "\n",
    "    # Combine predictions with actual classes\n",
    "    actual_class_test = df_test['best quality'].reset_index(drop=True)\n",
    "    model_output = pd.concat([predictions, actual_class_test], axis=1)\n",
    "\n",
    "    # Rename columns for clarity\n",
    "    model_output.columns = ['Predicted Wine Quality', 'Actual Wine Quality']\n",
    "\n",
    "    # Display the final output\n",
    "    print(model_output)\n",
    "else:\n",
    "    print(f\"Request failed with status code: {response.status_code}\")\n",
    "    print(f\"Response content: {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92961bc",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
